{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1190e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46290dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: rid of all columns that are mostly unfilled and patients who declined to answer a question\n",
    "cerv_data = pd.read_csv('risk_factors_cervical_cancer.csv', na_values=[\"?\"])\n",
    "print(len(cerv_data.columns))\n",
    "cerv_data = cerv_data.drop(columns =['STDs: Time since last diagnosis','STDs: Time since first diagnosis'])\n",
    "cerv_data = cerv_data.dropna()\n",
    "#print(cerv_data)\n",
    "x, y = cerv_data.iloc[:,:-4], cerv_data.iloc[:,-4:]\n",
    "# print(x)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix utilities\n",
    "from IPython.display import HTML\n",
    "\n",
    "def print_confusion(cm):\n",
    "    column_names = pd.DataFrame([['Predicted', '-'],\n",
    "                                 ['Predicted', '+']],\n",
    "                                 columns=['', ''])\n",
    "    row_names = pd.DataFrame([['Observed', '-'],\n",
    "                              ['Observed', '+']],\n",
    "                              columns=['', ''])\n",
    "    columns = pd.MultiIndex.from_frame(column_names)\n",
    "    index = pd.MultiIndex.from_frame(row_names)\n",
    "    display(pd.DataFrame(cm, index=index, columns=columns))\n",
    "\n",
    "def get_score(cm):\n",
    "    return (cm[0,0]+cm[1,1])/np.sum(cm)\n",
    "\n",
    "def get_fp_rate(cm):\n",
    "    return cm[0,1]/(cm[0,0]+cm[0,1])\n",
    "\n",
    "def get_fn_rate(cm):\n",
    "    return cm[1,0]/(cm[1,1]+cm[1,0])\n",
    "\n",
    "def display_model_stats(cm, name):\n",
    "    display(HTML('''\n",
    "        <div class=\"row\">\n",
    "        <style scoped>\n",
    "            tr th {{\n",
    "                font-weight: 600;\n",
    "                text-align: center;\n",
    "            }}\n",
    "            thead th {{\n",
    "                font-weight: bold;\n",
    "                text-align: center;\n",
    "            }}\n",
    "            .rotate {{\n",
    "                transform: rotate(-180deg);\n",
    "                writing-mode: vertical-rl;\n",
    "                margin: 0em;\n",
    "            }}\n",
    "            .row {{ display: flex; }}\n",
    "            .column {{ padding: 5px; }}\n",
    "        </style>\n",
    "        <div class=\"column\">\n",
    "            <table>\n",
    "            <thead>\n",
    "                <th colspan=\"4\">{0}</th>\n",
    "            </thead>\n",
    "            <tr>\n",
    "                <td rowspan=\"2\" colspan=\"2\"></td>\n",
    "                <th colspan=\"2\">Predicted</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th>-</td>\n",
    "                <th>+</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th rowspan=\"2\"><p class=\"rotate\">Observed</p></th>\n",
    "                <th>-</td>\n",
    "                <td>{1}</td>\n",
    "                <td>{2}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th>+</td>\n",
    "                <td>{3}</td>\n",
    "                <td>{4}</td>\n",
    "            </tr>\n",
    "            </table>\n",
    "        </div>\n",
    "        <div class=\"column\">\n",
    "            <table>\n",
    "            <thead>\n",
    "                <th colspan=\"2\">{0}</th>\n",
    "            </thead>\n",
    "            <tr>\n",
    "                <th>Total accuracy</th>\n",
    "                <td>{5:.3}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th>False positive rate</th>\n",
    "                <td>{6:.3}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th>False negative rate</th>\n",
    "                <td>{7:.3}</td>\n",
    "            </tr>\n",
    "            </table>\n",
    "        </div>\n",
    "        </div>\n",
    "    '''.format(\n",
    "        name,\n",
    "        cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1],\n",
    "        get_score(cm), get_fp_rate(cm), get_fn_rate(cm)\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6808bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Logistic regression ######\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "hinselmann, schiller, citology, biopsy = y.loc[:, 'Hinselmann'], y.loc[:, 'Schiller'], y.loc[:, 'Citology'], y.loc[:, 'Biopsy']\n",
    "\n",
    "lr_pipe = Pipeline([('scale', StandardScaler()), ('logreg', LogisticRegression())])\n",
    "\n",
    "# Direct fitting\n",
    "def direct_fit_classifier(pipe, x, y, balanced_step_name=None):\n",
    "    if balanced_step_name:\n",
    "        fit_params = {'{0}__sample_weight'.format(balanced_step_name): compute_sample_weight('balanced', y)}\n",
    "    else:\n",
    "        fit_params = {}\n",
    "    pipe.fit(x, y, **fit_params)\n",
    "    return confusion_matrix(y, pipe.predict(x))\n",
    "\n",
    "# Cross-validation\n",
    "def cv_classifier(pipe, x, y, cv, balanced_step_name=None):\n",
    "    ypred = np.empty(x.shape[0])\n",
    "    for train_i, test_i in cv.split(x):\n",
    "        if balanced_step_name:\n",
    "            fit_params = {'{0}__sample_weight'.format(balanced_step_name): compute_sample_weight('balanced', y.iloc[train_i])}\n",
    "        else:\n",
    "            fit_params = {}\n",
    "        pipe.fit(x.iloc[train_i], y.iloc[train_i], **fit_params)\n",
    "        ypred[test_i] = pipe.predict(x.iloc[test_i])\n",
    "    return confusion_matrix(y, ypred)\n",
    "\n",
    "for outcome, name in zip([hinselmann, schiller, citology, biopsy],\n",
    "                         ['Hinselmann', 'Schiller', 'Citology', 'Biopsy']):\n",
    "    direct_cm = direct_fit_classifier(lr_pipe, x, outcome, 'logreg')\n",
    "    cv_cm = cv_classifier(lr_pipe, x, outcome, KFold(shuffle=True), 'logreg')\n",
    "\n",
    "    display_model_stats(direct_cm, '{0} upon fitting'.format(name))\n",
    "    display_model_stats(cv_cm, '{0} upon CV'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Support vector machines ######\n",
    "#we will have to play with c value and kernel\n",
    "svc_model = Pipeline([('scale', StandardScaler()), ('svm', SVC(C=1000, kernel='rbf'))])\n",
    "hinselmann_arr = np.array(hinselmann)\n",
    "svc_model.fit(x, hinselmann_arr)\n",
    "hinselmann_predict = svc_model.predict(x)\n",
    "#print(hinselmann_predict)\n",
    "print(cv_classifier(svc_model, x, hinselmann, KFold()))\n",
    "\n",
    "schiller_arr = np.array(schiller)\n",
    "svc_model.fit(x, schiller_arr)\n",
    "schiller_predict = svc_model.predict(x)\n",
    "#print(schiller_predict)\n",
    "print(cv_classifier(svc_model, x, schiller, KFold()))\n",
    "\n",
    "citology_arr = np.array(citology)\n",
    "svc_model.fit(x, citology_arr)\n",
    "citology_predict = svc_model.predict(x)\n",
    "#print(citology_predict)\n",
    "print(cv_classifier(svc_model, x, citology, KFold()))\n",
    "\n",
    "biopsy_arr = np.array(biopsy)\n",
    "svc_model.fit(x, biopsy_arr)\n",
    "biopsy_predict = svc_model.predict(x)\n",
    "#print(biopsy_predict)\n",
    "print(cv_classifier(svc_model, x, biopsy, KFold()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308bfac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [hinselmann, schiller, citology, biopsy]\n",
    "kernels_options = ['rbf', 'poly']\n",
    "cv_data = np.zeros((4,2,20))\n",
    "c_values = np.logspace(-4,5,20)\n",
    "for a in range(4):\n",
    "    for i, b in enumerate(c_values):\n",
    "        for c in range(2):\n",
    "            svc_model = Pipeline([('scale', StandardScaler()), ('svm', SVC(C=b, kernel=kernels_options[c]))])\n",
    "            direct_cm = direct_fit_classifier(svc_model, x, tests[a])\n",
    "            cv_cm = cv_classifier(svc_model, x, tests[a], KFold())\n",
    "            display_model_stats(direct_cm, '{0} upon fitting'.format(name))\n",
    "            display_model_stats(cv_cm, '{0} upon CV'.format(name))\n",
    "            cv_data[a,c,i] = get_score(cv_cm)\n",
    "            print(tests[a])\n",
    "            print(kernels_options[c])\n",
    "            print(c_values[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dec1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(4):\n",
    "    for b in range(2):\n",
    "        plt.scatter(c_values,cv_data[a,b,:])\n",
    "        plt.title('test ' + f'{tests[a]}' + 'kernel ' + f'{kernels_options[b]}')\n",
    "        plt.xscale('log')\n",
    "        plt.show()\n",
    "        print(max(cv_data[a,b,:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
